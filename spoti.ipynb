{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME SIGNATURE PREDICTION OF GIVEN SPOTIFY SONGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this repository, I'll try to predict time signature of the spotify songs in our dataset. <br>\n",
    "**Time Signature** (also known as meter signature, metre signature, or measure signature) is a notational convention used in Western musical notation to specify how many beats (pulses) are to be contained in each bar and which note value is to be given one beat. <br>\n",
    "In this dataset, we have 4 kinds of time signatures : 1,3,4,5. As we will classify our dataset according to these 4 time signatures, we'll have multiclass classification problem. <br>\n",
    "We'll do this by Scikit-Learn <br>\n",
    "To do that, first, we need to import the necessary libraries & our dataset ,and then fit our dataset for our ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING OUR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"C:\\\\Users\\\\talfi\\\\python\\\\TensorFlow\\\\1.Regression\\\\self\\\\spoti\\\\genres_v2.csv\"\n",
    "url2= \"C:\\\\Users\\\\talfi\\\\python\\\\TensorFlow\\\\1.Regression\\\\self\\\\spoti\\\\playlists.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talfi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>genre</th>\n",
       "      <th>song_name</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.814</td>\n",
       "      <td>2</td>\n",
       "      <td>-7.364</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>...</td>\n",
       "      <td>2Vc6NJ9PW9gD9q343XFRKx</td>\n",
       "      <td>spotify:track:2Vc6NJ9PW9gD9q343XFRKx</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2Vc6NJ9PW9gD...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2Vc6...</td>\n",
       "      <td>124539</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>Mercury: Retrograde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.719</td>\n",
       "      <td>0.493</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>...</td>\n",
       "      <td>7pgJBLVz5VmnL7uGHmRj6p</td>\n",
       "      <td>spotify:track:7pgJBLVz5VmnL7uGHmRj6p</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/7pgJBLVz5Vmn...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/7pgJ...</td>\n",
       "      <td>224427</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>Pathology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.893</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.783</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>...</td>\n",
       "      <td>0vSWgAlfpye0WCGeNmuNhy</td>\n",
       "      <td>spotify:track:0vSWgAlfpye0WCGeNmuNhy</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0vSWgAlfpye0...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0vSW...</td>\n",
       "      <td>98821</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>Symbiote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.710</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>...</td>\n",
       "      <td>0VSXnJqQkwuH2ei1nOQ1nu</td>\n",
       "      <td>spotify:track:0VSXnJqQkwuH2ei1nOQ1nu</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0VSXnJqQkwuH...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0VSX...</td>\n",
       "      <td>123661</td>\n",
       "      <td>3</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>ProductOfDrugs (Prod. The Virus and Antidote)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.624</td>\n",
       "      <td>2</td>\n",
       "      <td>-7.668</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>...</td>\n",
       "      <td>4jCeguq9rMTlbMmPHuO7S3</td>\n",
       "      <td>spotify:track:4jCeguq9rMTlbMmPHuO7S3</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/4jCeguq9rMTl...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4jCe...</td>\n",
       "      <td>123298</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>Venom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.831   0.814    2    -7.364     1       0.4200        0.0598   \n",
       "1         0.719   0.493    8    -7.230     1       0.0794        0.4010   \n",
       "2         0.850   0.893    5    -4.783     1       0.0623        0.0138   \n",
       "3         0.476   0.781    0    -4.710     1       0.1030        0.0237   \n",
       "4         0.798   0.624    2    -7.668     1       0.2930        0.2170   \n",
       "\n",
       "   instrumentalness  liveness  valence  ...                      id  \\\n",
       "0          0.013400    0.0556   0.3890  ...  2Vc6NJ9PW9gD9q343XFRKx   \n",
       "1          0.000000    0.1180   0.1240  ...  7pgJBLVz5VmnL7uGHmRj6p   \n",
       "2          0.000004    0.3720   0.0391  ...  0vSWgAlfpye0WCGeNmuNhy   \n",
       "3          0.000000    0.1140   0.1750  ...  0VSXnJqQkwuH2ei1nOQ1nu   \n",
       "4          0.000000    0.1660   0.5910  ...  4jCeguq9rMTlbMmPHuO7S3   \n",
       "\n",
       "                                    uri  \\\n",
       "0  spotify:track:2Vc6NJ9PW9gD9q343XFRKx   \n",
       "1  spotify:track:7pgJBLVz5VmnL7uGHmRj6p   \n",
       "2  spotify:track:0vSWgAlfpye0WCGeNmuNhy   \n",
       "3  spotify:track:0VSXnJqQkwuH2ei1nOQ1nu   \n",
       "4  spotify:track:4jCeguq9rMTlbMmPHuO7S3   \n",
       "\n",
       "                                          track_href  \\\n",
       "0  https://api.spotify.com/v1/tracks/2Vc6NJ9PW9gD...   \n",
       "1  https://api.spotify.com/v1/tracks/7pgJBLVz5Vmn...   \n",
       "2  https://api.spotify.com/v1/tracks/0vSWgAlfpye0...   \n",
       "3  https://api.spotify.com/v1/tracks/0VSXnJqQkwuH...   \n",
       "4  https://api.spotify.com/v1/tracks/4jCeguq9rMTl...   \n",
       "\n",
       "                                        analysis_url duration_ms  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/2Vc6...      124539   \n",
       "1  https://api.spotify.com/v1/audio-analysis/7pgJ...      224427   \n",
       "2  https://api.spotify.com/v1/audio-analysis/0vSW...       98821   \n",
       "3  https://api.spotify.com/v1/audio-analysis/0VSX...      123661   \n",
       "4  https://api.spotify.com/v1/audio-analysis/4jCe...      123298   \n",
       "\n",
       "  time_signature      genre                                      song_name  \\\n",
       "0              4  Dark Trap                            Mercury: Retrograde   \n",
       "1              4  Dark Trap                                      Pathology   \n",
       "2              4  Dark Trap                                       Symbiote   \n",
       "3              3  Dark Trap  ProductOfDrugs (Prod. The Virus and Antidote)   \n",
       "4              4  Dark Trap                                          Venom   \n",
       "\n",
       "  Unnamed: 0 title  \n",
       "0        NaN   NaN  \n",
       "1        NaN   NaN  \n",
       "2        NaN   NaN  \n",
       "3        NaN   NaN  \n",
       "4        NaN   NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoti = pd.read_csv(url1, encoding='utf-8', quotechar='\"')\n",
    "spoti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FITTING OUR DATASET FOR ML MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this with two ways. **First** one is `pd.get_dummies()` function. Actually, I've tried this but my computer's ram couldn't handle it. Thus, I'll go with the **second** way; dropping object columns. <br>\n",
    "Normally, this option is not much prefareble because of the data loss, but as our df has excessive amount of rows and cols, I think we'll be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability        float64\n",
       "energy              float64\n",
       "key                   int64\n",
       "loudness            float64\n",
       "mode                  int64\n",
       "speechiness         float64\n",
       "acousticness        float64\n",
       "instrumentalness    float64\n",
       "liveness            float64\n",
       "valence             float64\n",
       "tempo               float64\n",
       "type                 object\n",
       "id                   object\n",
       "uri                  object\n",
       "track_href           object\n",
       "analysis_url         object\n",
       "duration_ms           int64\n",
       "time_signature        int64\n",
       "genre                object\n",
       "song_name            object\n",
       "Unnamed: 0          float64\n",
       "title                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoti.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoti = spoti.drop(columns= [\"type\", \"id\", \"uri\", \"track_href\", \"analysis_url\", \"genre\", \"song_name\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability        float64\n",
       "energy              float64\n",
       "key                   int64\n",
       "loudness            float64\n",
       "mode                  int64\n",
       "speechiness         float64\n",
       "acousticness        float64\n",
       "instrumentalness    float64\n",
       "liveness            float64\n",
       "valence             float64\n",
       "tempo               float64\n",
       "duration_ms           int64\n",
       "time_signature        int64\n",
       "Unnamed: 0          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoti.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42305, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoti.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, 42305 rows and 15 columns are enough to train and test our model with both Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    40427\n",
       "3     1219\n",
       "5      509\n",
       "1      150\n",
       "Name: time_signature, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoti[\"time_signature\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, mostly we have 4 beats (pulses) are to be contained in each bar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start with the Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT LEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit-Learn, first, we'll look our classification_report. We'll classify our dataset by Support Vector Classification. We'll also use the sklearn's pipeline method. <br>\n",
    "Note, I am going to classify our dataset with different methods as much as possible to demonstrate my knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM\n",
    "In Scikit-Learn, first, we'll look our our classification_report by classifying our data with SVM. <br>\n",
    "* The classification report is about key metrics in a classification problem. We'll have precision, recall, f1-score and support for each class We'll trying to find. The recall means \"how many of this class we find over the whole number of element of this class\" <br>\n",
    "Then, we'll classify our dataset by Support Vector Classification from `sklearn.svm` <br>\n",
    "* `SVC` (Support Vector Classifier) is to fit to the data we provide, returning a \"best fit\" hyperplane that divides, or categorizes, our data.The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes. <br>\n",
    "We'll also use the `pipeline` method. <br>\n",
    "* Pipeline method equentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be â€˜transformsâ€™, that is, they must implement fit and transform methods.The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        38\n",
      "           3       0.00      0.00      0.00       305\n",
      "           4       0.96      1.00      0.98     10107\n",
      "           5       0.00      0.00      0.00       127\n",
      "\n",
      "    accuracy                           0.96     10577\n",
      "   macro avg       0.24      0.25      0.24     10577\n",
      "weighted avg       0.91      0.96      0.93     10577\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talfi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "steps = [(\"imputation\", SimpleImputer(missing_values=np.nan, strategy='most_frequent')),(\"SVM\", SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, X_test, y_train ,y_test = train_test_split(\n",
    "    spoti.drop(columns='time_signature'),\n",
    "    spoti[\"time_signature\"],\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=spoti[\"time_signature\"]\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our key metrics for classification problem. <br>\n",
    "As you spotted, we used the `SimpleImputer` <br>\n",
    "SimpleImputer is a scikit-learn class which is helpful in handling the missing data in the predictive model dataset. It replaces the NaN values with a specified placeholder. In this case, we'll replace our NaN  values with using the mean along\n",
    "      each column. <br>\n",
    "We'll use the simple imputer one more time. This time we'll use it without pipeline method. <br>\n",
    "As SimpleImputer method transfers our colnames into their index number, we'll rename our colnames as they used to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>Oth-N</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>Unnamed-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.814</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>156.985</td>\n",
       "      <td>124539.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10483.970645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.719</td>\n",
       "      <td>0.493</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-7.230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>115.080</td>\n",
       "      <td>224427.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10483.970645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.893</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>218.050</td>\n",
       "      <td>98821.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10483.970645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.831   0.814  2.0    -7.364   1.0       0.4200        0.0598   \n",
       "1         0.719   0.493  8.0    -7.230   1.0       0.0794        0.4010   \n",
       "2         0.850   0.893  5.0    -4.783   1.0       0.0623        0.0138   \n",
       "\n",
       "      Oth-N  instrumentalness  liveness  valence  duration_ms  time_signature  \\\n",
       "0  0.013400            0.0556    0.3890  156.985     124539.0             4.0   \n",
       "1  0.000000            0.1180    0.1240  115.080     224427.0             4.0   \n",
       "2  0.000004            0.3720    0.0391  218.050      98821.0             4.0   \n",
       "\n",
       "      Unnamed-0  \n",
       "0  10483.970645  \n",
       "1  10483.970645  \n",
       "2  10483.970645  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "imr = imr.fit(spoti)\n",
    "\n",
    "imputed_data = imr.transform(spoti)\n",
    "spoti = pd.DataFrame(imputed_data)\n",
    "spoti = spoti.rename(columns={0:\"danceability\", 1:\"energy\", 2:\"key\",3:\"loudness\",4:\"mode\",5:\"speechiness\",6:\"acousticness\",7:\"Oth-N\",8:\"instrumentalness\",9:\"liveness\",10:\"valence\",11:\"duration_ms\",12:\"time_signature\",13:\"Unnamed-0\"})\n",
    "spoti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability        float64\n",
       "energy              float64\n",
       "key                 float64\n",
       "loudness            float64\n",
       "mode                float64\n",
       "speechiness         float64\n",
       "acousticness        float64\n",
       "Oth-N               float64\n",
       "instrumentalness    float64\n",
       "liveness            float64\n",
       "valence             float64\n",
       "duration_ms         float64\n",
       "time_signature      float64\n",
       "Unnamed-0           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoti.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleImputer did one more thing; it transferred some our dataset's dtype from int64 to float64. Now, all dtypes are float64, and that is good for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MULTICLASS ROC AUC SCORE WITH LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to implement **roc auc score** <br>\n",
    "AUC - ROC curve is a performance measurement for the classification problems at various threshold settings. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. <br>\n",
    "As we are dealing with multiclass classification, we need to define new roc_auc_score_multiclass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "logreg = LogisticRegression()\n",
    "X_train, X_test, y_train ,y_test = train_test_split(\n",
    "    spoti.drop(columns='time_signature'),\n",
    "    spoti[\"time_signature\"],\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=spoti[\"time_signature\"]\n",
    ")\n",
    "logreg.fit(X_train, y_train)\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "  #creating a set of all the unique classes using the actual class list\n",
    "  unique_class = set(actual_class)\n",
    "  roc_auc_dict = {}\n",
    "  for per_class in unique_class:\n",
    "    #creating a list of all the classes except the current class \n",
    "    other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "    #marking the current class as 1 and all other classes as 0\n",
    "    new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "    new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "    #using the sklearn metrics method to calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "    roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "  return roc_auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0.5, 3.0: 0.5, 4.0: 0.5, 5.0: 0.5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "roc_auc_score_multiclass(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC SCORE AND BEST PIPELINE STEPS WITH TPOT CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to find auc score one more time, but this time with TPOT classifier. <br>\n",
    "TPOT is an open-source library for performing AutoML in Python. It makes use of the popular Scikit-Learn machine learning library for data transforms and machine learning algorithms and uses a Genetic Programming stochastic global search procedure to efficiently discover a top-performing model pipeline for a given dataset. <br>\n",
    "* Thanks to TPOT, we don't need to define roc_auc_score_multiclass because TPOT automatically handles it. <br>\n",
    "* We'll also discover best pipeline steps with TPOT. That is, TPOT will tell us what pipeline steps to use to reach maximum success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talfi\\anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96a1073d0c4476786dcb8200191407f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9615166332756907\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=73, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9615166332756907\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=73, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "-2\t0.9623991534164469\tKNeighborsClassifier(MinMaxScaler(input_matrix), KNeighborsClassifier__n_neighbors=21, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9615166332756907\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=73, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "-2\t0.9624621902145691\tKNeighborsClassifier(StandardScaler(input_matrix), KNeighborsClassifier__n_neighbors=21, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9615166332756907\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=73, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "-2\t0.9636283486281141\tKNeighborsClassifier(SelectPercentile(input_matrix, SelectPercentile__percentile=41), KNeighborsClassifier__n_neighbors=92, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9615166332756907\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=73, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "-2\t0.9636283486281141\tKNeighborsClassifier(SelectPercentile(input_matrix, SelectPercentile__percentile=41), KNeighborsClassifier__n_neighbors=92, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "AUC score: {1.0: 0.5, 3.0: 0.3836065573770492, 4.0: 0.5755319148936171, 5.0: 0.5033971291866028}\n",
      "\n",
      "Best pipeline steps:\n",
      "1. SelectPercentile(percentile=41)\n",
      "2. KNeighborsClassifier(n_neighbors=92, p=1, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=20,\n",
    "    verbosity=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    disable_update_check=True,\n",
    "    config_dict='TPOT light'\n",
    ")\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# AUC score for tpot model\n",
    "tpot_auc_score = roc_auc_score_multiclass(y_test, tpot.predict_proba(X_test)[:, 1])\n",
    "print(f'\\nAUC score:',tpot_auc_score)\n",
    "\n",
    "# Print best pipeline steps\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
    "    # Print idx and transform\n",
    "    print(f'{idx}. {transform}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its seems that best classifier for this case is `KNeighborsClassifier(n_neighbors=92, p=1, weights='distance')` <br>\n",
    "The best percentile is 41 %. <br>\n",
    "Well, let's go with these two then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9634111751914531"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 92, p=1, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96 %  of test set accuracy. Hmm.. Not bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
